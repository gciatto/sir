In this section we describe and motivate the \EKF{} algorithm allowing us to face the \SLAM{} problem.

\subsection{The system state}
	Here we define the concept of (system) \emph{state}, which will be pervasively used in the following.
	
	The system state $\vect{x}_t$ consist of the robot pose vector $\vect{r}_t$ and the position vector $\vect{m}_{1},\, \vect{m}_{2},\, \ldots,\, \vect{m}_{M}$ of each known landmark. It is indeed defined as the concatenation of such vectors:
	\[
		\vect{x}_t \stackrel{def}{=}
		\left(\begin{array}{c}
			\vect{r}_t \\ \vect{m}_{1} \\ \vect{m}_{2} \\ \vdots \\ \vect{m}_{M}
		\end{array}\right)
		=
		\left(\begin{array}{c}
			\vect{r}_t \\ \vect{m}
		\end{array}\right)
		\in \mathbb{R}^{n + M \cdot q}
	\]
	where $\vect{m} \in \mathbb{R}^{M \cdot q}$ is a compact way to express the concatenation of all the known landmarks position vectors.
	
	The purpose of the \EKF-\SLAM{} algorithm is to produce and update an estimation of the state vector exploiting the exteroceptive and proprioceptive data. 
	It is important to understand that the robot \emph{cannot} know its exact state because of the noise afflicting sensors and actuators.
	Hence, we assume the state to be a multi-normal random vector (please refer to Appendix \ref{app.multinormal} for details) for which we assume to know the initial mean $\bvect{x}_0$ and covariances matrix $\Sigma_0$.
	The \EKF-\SLAM{} algorithm allows to compute the mean $\bvect{x}_t$ and covariances matrix $\Sigma_t$ of the current state as a function of the mean $\bvect{x}_{t - 1}$ and covariances matrix $\Sigma_{t - 1}$ of the previous state.
	The mean $\bvect{x}_t$ represents the most recent estimation of the robot pose and landmarks positions, while the covariances matrix $\Sigma_t$ stores the uncertainty of such estimation.
	
	Generally speaking, the mean and covariances are in the following form:
	\[
		\bvect{x}_t =
		\left(\begin{array}{c}
			\bvect{r}_t \\ \bvect{m}_{1,t} \\ \bvect{m}_{2,t} \\ \vdots \\ \bvect{m}_{M,t}
		\end{array}\right)
		=
		\left(\begin{array}{c}
			\bvect{r}_t \\ \bvect{m}_t
		\end{array}\right)
		\in \mathbb{R}^{n + M \cdot q}
	\]
	(notice that the expected position $\bvect{m}_{i,t}$ of any landmark may vary --- \ie{} be corrected --- as time progresses, while the actual position $\vect{m}_{i}$ is supposed not to change)
	\[
		\Sigma_t =
		\left(\begin{array}{cc}
			\sigma_{\vect{r},\vect{r}, t} & \sigma_{\vect{r},\vect{m}, t} \\
			\sigma_{\vect{m},\vect{r}, t} & \sigma_{\vect{m},\vect{m}, t}
		\end{array}\right)
		\in \mathcal{M}_{(n + M \cdot q) \times (n + M \cdot q)}(\mathbb{R})
	\]
	where $\sigma_{\vect{r},\vect{r}, t} \in \mathcal{M}_{n \times n}(\mathbb{R})$ is the sub-matrix containing the covariances of the pose, $\sigma_{\vect{r},\vect{m}, t} \in \mathcal{M}_{n \times M \cdot q}(\mathbb{R})$ is the sub-matrix containing the covariances of the pose w.r.t. the landmark positions,  $\sigma_{\vect{m},\vect{r}, t} = \sigma^\top_{\vect{r},\vect{m}, t}$, since $\Sigma_t$ must be symmetric, and $\sigma_{\vect{m},\vect{m}, t} \in \mathcal{M}_{M \cdot q \times M \cdot q}(\mathbb{R})$ is the sub-matrix containing the covariances of the landmark positions.
	
	Please notice that $M$, \ie{} the number of currently known and mapped landmarks, may actually vary as the robot moves, since more landmarks may be discovered.
	
	\subsubsection{The initial state}
	
		As stated before, we (and the robot) assume that the global frame coincides with the robot frame at the very first step of the \SLAM{} algorithm. We also assume that the robot has no prior knowledge about the landmarks positions, \ie{} $M_0 = 0$.
		This implies that:
		\[
			\bvect{x}_0 = \bvect{r}_0 = \vect{0}
			\hspace{2cm}
			\Sigma_0 = \vect{0}
		\]
		meaning that the robot is supposed to have \emph{null uncertainty} about its initial position to be the origin of the global frame.
		
		In what follows we will explain:
		\begin{itemize}
			\item How $\bvect{x}_t$ and $\Sigma_t$ can be extended when a measurement vector $\vect{s}$ detects an unknown landmark
			\item How $\bvect{x}_t$ and $\Sigma_t$ can be computed as functions of $\bvect{x}_{t-1}$ and $\Sigma_{t-1}$, taking into account the last control vector $\vect{u}_t$ and some measurement vector $\vect{s}$ relative to some known landmark
		\end{itemize}
		
\subsection{Handling the noise}
	Here we discuss about how to model the intrinsic noise afflicting the robot sensors and actuators.
	
	\subsubsection{The system noise}
		Whenever the control software imposes (resp. receives) a control vector $\vect{u}_t$ to the robot actuators (resp. from the proprioceptive sensor), we assume such data to be inherently altered by the \emph{system} noise $\vect{\varepsilon}_t \in \mathbb{R}^m$, \ie{} the actual control vector perceived by the actuators (resp. proprioceptive sensor) is:
		\[
			{\vect{u}'}_t = \vect{u}_t + \vect{\varepsilon}_t
		\]
		For what concerns the \EKF{}, it is important for $\vect{\varepsilon}_t$ to be modeled as a multi-normal random vector with null mean and covariances matrix $E \in \mathcal{M}_{m \times m}(\mathbb{R})$.
		
		We can therefore consider the control vector $\bvect{u}_t$ provided to the \EKF{} to be the expected value of the multi-normally distributed random vector ${\vect{u}'}_t$, having covariances matrix $E$.
		
		\paragraph{Example: Differential robot on the plane.}
			In this case we assume the left and right wheel actuators to be affected by a normally distributed error with null mean and standard deviations $\sigma_l$ and $\sigma_r$ meters per second, respectively.
			This means that, whenever the velocity $v_l$ (resp. $v_r$) is imposed to the left (resp. right) wheel actuator, the real speed of the left (resp. right) wheel will be $v_l + \varepsilon_l$ (resp. $v_r + \varepsilon_r$), where $\varepsilon_l$ (resp. $\varepsilon_r$) will be in $[\, -3\sigma_l, +3\sigma_l \,]$ (resp. $[\, -3\sigma_r, +3\sigma_r \,]$) with about 99\% probability.
			
			Under such hypotheses, the covariances matrix of $\vect{\varepsilon} = (\varepsilon_l,\, \varepsilon_r)^\top$ is:
			\[
				E = 
				\left(\begin{array}{cc}
					\sigma^2_l & 0 \\
					0 & \sigma^2_r
				\end{array}\right)
			\]
			Notice that here we are implicitly supposing the left and right error to be uncorrelated, which may be, in general, not true\footnote{\label{sec.ekf.not_sure}not sure about this, TO-DO: check}.
			
	\subsubsection{The observation noise}
		Whenever the control software receives a measurement vector $\vect{s}$ from its exteroceptive sensor, we assume such data to be inherently altered be the \emph{observation} noise $\vect{\delta} \in \mathbb{R}^p$, \ie{} the actual measurement vector produced by the sensor is:
		\[
			\vect{s}' = \vect{s} + \vect{\delta}
		\]
		For what concerns the \EKF{}, it is important for $\vect{\delta}$ to be modeled as a multi-normal random vector with null mean and covariances matrix $\Delta \in \mathcal{M}_{p \times p}(\mathbb{R})$
		
		We can therefore consider each measurement vector $\bvect{s}$ provided to the \EKF{} to be the expected value of some multi-normally distributed random vector $\vect{s}'$, having covariances matrix $\Delta$.
		
		\paragraph{Example: Laser scanner on top of a robot.}
			In this case we assume the laser sensor to be characterized by a normally distributed error with null mean for both the distance ($\delta_\rho$) and the angle ($\delta_\alpha$). The standard deviations of the distance error and the angular error are $\sigma_\rho$ meters and $\sigma_\alpha$ radians, respectively.
			
			Under such hypotheses, the covariances matrix of $\vect{\delta} = (\delta_\rho,\, \delta_\alpha)^\top$ is:
			\[
				\Delta =
				\left(\begin{array}{cc}
					\sigma^2_\rho & 0 \\
					0 & \sigma^2_\alpha
				\end{array}\right)
			\]
			Notice that here we are implicitly assuming that the distance and angle error are uncorrelated and that the distance error does not depend on the distance itself, which may be, in general, not true\footnoteref{sec.ekf.not_sure}.
		
\subsection{The prediction phase}
	In this phase the motion model $g(\cdot)$ is exploited to produce an estimation of the current robot state $\bvect{x}_t$ taking into account the previous robot state $\bvect{x}_{t-1}$ and the last control vector $\bvect{u}_t$.
	The uncertainty about the system state $\Sigma_t$ is computed accordingly.
	
	Conceptually, this step is simple: the robot just needs to compute\footnote{\label{sec.ekf.alert}\notationAlert}
	\[
		\vect{x} \leftarrow \hat{g}(\vect{x},\, \vect{u})
	\]
	where $\hat{g}(\cdot)$ is the function applying the motion model $g(\cdot)$ to the first $n$ components of $\vect{x}$ and leaving the others unchanged\footnoteref{sec.ekf.alert}:
	\[
		\vect{x} = 
		\left(\begin{array}{c}
			\vect{r} \\ \vect{m}
		\end{array}\right)
		\leftarrow
		\left(\begin{array}{c}
			g(\vect{r},\, \vect{u}) \\ \vect{m}
		\end{array}\right) 
		= \hat{g}(\vect{x},\, \vect{u})
	\]
	
	Unfortunately, the robot never knows the \emph{real} system state or control vector or landmark positions, but it only knows their means and covariances as multi-normal variables.
	Mathematically, this step is complicated by $g(\cdot)$ being, in general, non-linear.
	So, while applying a linear transformation to the moments of some multi-normal variables, as explained in Appendix \ref{app.multinormal}, surely produces the moments of a multi-normal variable; applying a non-linear transformation does not guarantee so.
	This limitation is overcome by linearizing the $\hat{g}(\cdot)$ function into the point $(\bvect{x}_{t-1},\, \bvect{u}_{t})^\top$ as explained in Appendix \ref{app.jacobian}.
	
	Hence, the predicted robot state mean $\bvect{x}_t$ is computed as follows\footnoteref{sec.ekf.alert}:
	\begin{equation}
		\label{eq.prediction.mean.update}
		\bvect{x} = 
		\left(\begin{array}{c}
			\bvect{r} \\ \bvect{m}
		\end{array}\right)
		\leftarrow
		\left(\begin{array}{c}
			g(\bvect{r},\, \bvect{u}) \\ \bvect{m}
		\end{array}\right)
		= \hat{g}(\bvect{x},\, \bvect{u})
	\end{equation}
	assuming that the robot motion do not affect the landmark positions.
	Linearizing $\hat{g}(\cdot)$ allows us to compute the predicted robot state covariances matrix $\Sigma_t$.
	Such step is usually presented as follows: %\footnoteref{sec.ekf.alert}:
	\begin{equation}
		\label{eq.prediction.sigma.jacobians}
		\Sigma_t = \hat{G}_{\vect{x}} \cdot \Sigma_{t-1} \cdot \hat{G}^\top_{\vect{x}} \ + \ \hat{G}_{\vect{u}} \cdot E \cdot \hat{G}^\top_{\vect{u}}
	\end{equation}
	where $\hat{G}_{\vect{x}} = \partial \hat{g}(\bvect{x}_{t-1},\, \bvect{u}_{t}) / \partial \vect{x}$ and $\hat{G}_{\vect{u}} = \partial \hat{g}(\bvect{x}_{t-1},\, \bvect{u}_{t}) / \partial \vect{u}$ are the Jacobians of the $\hat{g}(\cdot)$ function into the point $(\bvect{x}_{t-1},\, \bvect{u}_{t})^\top$ w.r.t. the system state and the control, respectively, and $E$ is the covariances matrix of the system noise. 
	
	Since we assumed the $\hat{g}(\cdot)$ function not affecting the landmarks positions, Equation \ref{eq.prediction.sigma.jacobians} reduces to the following update rules\footnoteref{sec.ekf.alert}:
	\begin{equation}
		\label{eq.prediction.covs.update.rr}
		\sigma_{\vect{r},\vect{r}} \leftarrow G_{\vect{r}} \cdot \sigma_{\vect{r},\vect{r}} \cdot G^\top_{\vect{r}} \ + \ G_{\vect{u}} \cdot E \cdot G^\top_{\vect{u}}
	\end{equation}
	\begin{equation}
		\label{eq.prediction.covs.update.rm}
		\sigma_{\vect{r},\vect{m}} \leftarrow G_{\vect{r}} \cdot \sigma_{\vect{r},\vect{m}}
	\end{equation}
	\begin{equation}
		\label{eq.prediction.covs.update.mr}
		\sigma_{\vect{m},\vect{r}} \leftarrow \sigma^\top_{\vect{r},\vect{m}}
	\end{equation}
	\begin{equation}
		\label{eq.prediction.covs.update.mm}
		\sigma_{\vect{m},\vect{m}} \leftarrow \sigma_{\vect{m},\vect{m}}
	\end{equation}
	where $G_{\vect{x}} = \partial g(\bvect{x}_{t-1},\, \bvect{u}_{t}) / \partial \vect{x}$ and $G_{\vect{u}} = \partial g(\bvect{x}_{t-1},\, \bvect{u}_{t}) / \partial \vect{u}$ are the Jacobians of the motion model $g(\cdot)$ into the point $(\bvect{x}_{t-1},\, \bvect{u}_{t})^\top$ w.r.t. the system state and the control, respectively.
	
	Notice that, under such assumptions, the uncertainty related to the landmarks positions is not affected by the robot motion. 
	
	\vspace{1cm}
	\begin{recap}
		The prediction phase consists of the update rules expressed by equations \ref{eq.prediction.mean.update}, \ref{eq.prediction.covs.update.rr}, \ref{eq.prediction.covs.update.rm}, \ref{eq.prediction.covs.update.mr} and \ref{eq.prediction.covs.update.mm}.
	\end{recap}
	
\subsection{The observation phase}
	\label{sec.ekf.observation}
	Suppose that $M > 0$, \ie{} the robot already knows some landmarks positions, and suppose its exteroceptive sensor produced a measurement vector $\bvect{s}_i$ which allowed to \emph{somehow} recognize the $i$-th landmark, whose currently estimated position is $\bvect{m}_{i,t}$ with uncertainty $\sigma_{\vect{m}_i,\vect{m}_i,t}$.
	
	This phase exploits the direct observation model $h(\cdot)$ to estimate the moments of the multi-normally distributed random vector $\vect{z} \in \mathbb{R}^p$ (a.k.a. the \emph{correction}) representing the difference between the actual measurement $\bvect{s}_i$ and the expected one $h(\bvect{r}_t,\, \bvect{m}_{i,t})$ considering the current robot pose $\bvect{r}_t$.
	
	Conceptually this step is simple: the robot just needs to compute: %\footnoteref{sec.ekf.alert}:
	\[
		\vect{z} = \vect{s} - \hat{h}_i(\vect{x}_t) = \vect{s} - h(\vect{r}_t,\, \vect{m}_i)
	\]
	where $\hat{h}_i(\cdot)$ is the function applying the direct observation model to the current robot pose $\vect{r}_t$ and the $i$-th landmark position $\vect{m}_i$ and ignoring the other landmarks stored into the state vector $\vect{x}_t$.
	
	Sadly, as for the prediction phase, the robot never knows its \emph{real} pose or any landmark position, but it only knows their first and second order moments as multi-normal variables. Mathematically, this step is complicated by $h(\cdot)$ being, in general, non-linear.
	As for the motion model, this limitation is overcome by linearizing the $\hat{h}_i(\cdot)$ function into the point $\bvect{x}_t$, as explained in Appendix \ref{app.jacobian}.
	
	So, the correction mean $\bvect{z}$ is computed as follows:
	\begin{equation}
		\label{eq.observation.z}
		\bvect{z} = \bvect{s} - \hat{h}_i(\bvect{x}_t) % = \bvect{s} - h(\bvect{r}_t,\, \bvect{m}_i)
	\end{equation}
	Linearizing $\hat{h}_i(\cdot)$ allows us to compute the correction covariances matrix $Z \in \mathcal{M}_{p \times p}(\mathbb{R})$. Such step is usually presented as follows:
	\begin{equation}
		\label{eq.observation.Z}
		Z = \hat{H}_{i,\vect{x}} \cdot \Sigma_t \cdot \hat{H}^\top_{i,\vect{x}} + \Delta
	\end{equation}
	where $\hat{H}_{i,\vect{x}} = \partial \hat{h}_i(\bvect{x}_{t}) / \partial \vect{x}$ is the Jacobian of the $\hat{h}_i(\cdot)$ function into the point $\bvect{x}_{t}$ w.r.t. the system state, and $\Delta$ is the covariances matrix of the observation noise.
	
	The $\hat{h}_i(\cdot)$ function, by definition, only takes into account $\bvect{r}_t$ and $\bvect{m}_{i,t}$, and consequently it is easy to demonstrate that $\hat{H}_{i,\vect{x}}$ is in the form:
	\begin{equation}
		\label{eq.observation.sparse_jacobian}
		\hat{H}_{i,\vect{x}} = 
		\left(\begin{array}{cccccccc}
			H_{\vect{r}} & \vect{0} & \cdots & \vect{0} & H_{\vect{m}_i} & \vect{0} & \cdots & \vect{0}
		\end{array}\right)
	\end{equation}
	where $H_{\vect{r}} = \partial h(\bvect{r}_{t},\, \bvect{m}_{i,t}) / \partial \vect{r}$ and $H_{\vect{m}_i} = \partial h(\bvect{r}_{t},\, \bvect{m}_{i,t}) / \partial \vect{m}_i$ are the Jacobians of the observation model $h(\cdot)$ into the point $(\bvect{r}_{t},\, \bvect{m}_{i,t})^\top$ w.r.t. the robot pose and $i$-th landmark position, respectively.
	Thus, Equations \ref{eq.observation.z} and \ref{eq.observation.Z} reduce to:
	\begin{equation}
		\label{eq.observation.mean}
		\bvect{z} = \bvect{s} - h(\bvect{r}_t,\, \bvect{m}_i)
	\end{equation}
	\begin{equation}
		\label{eq.observation.covs}
		Z = 
		\left(\begin{array}{cc}
			H_{\vect{r}} & H_{\vect{m}_i}
		\end{array}\right)
		\cdot
		\left(\begin{array}{cc}
			\sigma_{\vect{r}, \vect{r}, t} & \sigma_{\vect{r}, \vect{m}_i, t} \\
			\sigma_{\vect{m_i}, \vect{r}, t} & \sigma_{\vect{m}_i, \vect{m}_i, t}
		\end{array}\right)
		\cdot
		\left(\begin{array}{c}
			H^\top_{\vect{r}} \\ H^\top_{\vect{m}_i}
		\end{array}\right)
		+ \Delta
	\end{equation}
	where $\Delta$ is the observation noise.
	
	\vspace{1cm}
	\begin{recap}
		The observation phase consists of Equations \ref{eq.observation.mean} and \ref{eq.observation.covs}.
	\end{recap}
	
\subsection{The correction phase}
	This phase exploits the correction moments $\bvect{z}$ and $Z$, produced by the observation phase for the $i$-th landmark, to correct the robot state moments $\bvect{x}_t$ and $\Sigma_t$ produced by the prediction phase. 
	In other words, the correction phase improves the estimation about the robot pose and the landmarks positions taking into account the difference between the expected and actual measurements of the $i$-th landmark.
	
	Such a step only consists of algebraic operations. 
	An clear intuition of what follows can be found in \cite[Unit C]{brenner204}.
	For a more exhaustive explanation, refer to \cite[Ch. 3]{thrun2005}.
	
	The correction phase is usually presented as composed by the following equations:
	\begin{equation}
		\label{eq.correction.K}
		K = \Sigma_t \cdot \hat{H}^\top_{i,\vect{x}} \cdot Z^{-1}
	\end{equation}
	\begin{equation}
		\label{eq.correction.x}
		\bvect{x}_t \leftarrow \bvect{x}_t + K \cdot \bvect{z}
	\end{equation}
	\begin{equation}
		\label{eq.correction.Sigma}
		\Sigma_t \leftarrow \Sigma_t \ - \ K \cdot Z \cdot K^\top
	\end{equation}
	where $K \in \mathcal{M}_{(n + M \cdot q) \times p}(\mathbb{R})$ is the so-called \emph{Kalman gain} and $\hat{H}_{i,\vect{x}}$ is the Jacobian of the function $\hat{h}_i$ into the point $\bvect{x}_t$ w.r.t. the state vector, as defined in Subsection \ref{sec.ekf.observation}.
	
	The Kalman gain definition can be simplified, since the Jacobian $\hat{H}_{i,\vect{x}}$ is sparse, as shown in Equation \ref{eq.observation.sparse_jacobian}.
	Therefore, Equation \ref{eq.correction.K} reduces to:
	\begin{equation}
		\label{eq.correction.kalman_gain}
		K = 
		\left(\begin{array}{cc}
			\sigma_{\vect{r}, \vect{r}, t} & \sigma_{\vect{r}, \vect{m}_i, t} \\
			\sigma_{\vect{m}, \vect{r}, t} & \sigma_{\vect{m}, \vect{m}_i, t}
		\end{array}\right)
		\cdot
		\left(\begin{array}{c}
			H^\top_{\vect{r}} \\ H^\top_{\vect{m}_i}
		\end{array}\right)
		\cdot
		Z^{-1}
	\end{equation}
	
	The new moments of the robot state, $\bvect{x}_t$ and $\Sigma_t$, produced by the correction phase, represent the outcome of the $t$-th step of the \EKF{} algorithm and, consequently, the input of the $(t+1)$-th prediction phase.
	
	\vspace{1cm}
	\begin{recap}
		The correction step consist of Equations \ref{eq.correction.kalman_gain}, \ref{eq.correction.x} and \ref{eq.correction.Sigma}.
	\end{recap}
	

\subsection{The recognition phase}
	This phase exploits the inverse observation model $\lambda(\cdot)$ to discriminate between known and unknown landmarks. 
	It is essentially a classification problem with $M + 1$ possible classes.
	Some unclassified measurement vector $\bvect{s}_?$, received by the exteroceptive sensor, is mapped into the corresponding point $\bvect{m}_?$ within the global frame, according to the inverse observation model and the current estimation of the robot pose $\bvect{r_t}$:
	\[
		\bvect{m}_? = \lambda(\bvect{r_t},\, \bvect{s}_?)
	\]
	The $\bvect{m}_?$ vector is then compared with every currently known landmark $\bvect{m}_{i,t}$ in $\bvect{x}_t$, in order to determine if it corresponds to one of them. 
	If it doesn't, it is considered a new landmark and the state vector is updated accordingly, as explained in Section \ref{sec.state_extension}.
	The way such comparison is performed is the actual core of the recognition phase. 
	Several strategies can be employed, some of them are described in the following examples.
	
	\paragraph{Example: Euclidean distance.}
		According to this strategy, the euclidean distance $d_E(\bvect{m}_?,\,\bvect{m}_{i,t})$ is computed for each $i = 1,\, \ldots,\, M$.
		The vector $\bvect{m}_?$ is considered coincident with the first $\bvect{m}_{i,t}$ such that $d_E \leq D_{min}$, where $D_{min}$ is some predefined distance threshold.
		
		The problem with this approach is that it does not take into account the uncertainty related to $\bvect{m}_?$ and each $\bvect{m}_?$.
		
	\paragraph{Example: Mahanolobis distance w.r.t. the $i$-th landmark.}
		This strategy exploits the information stored within the state covariances matrix $\Sigma_t$: its sub-matrix $\sigma_{\vect{m}_i,\vect{m}_i,t}$ is actually the current covariances matrix of the $i$-th landmark whose currently estimated position is $\bvect{m}_{i,t}$. 
		According to this method, the Mahalonobis distance\footnote{\label{sec.ekf.mahalobis}refer to Appendix \ref{app.mahalonobis}} $d_M(\bvect{m}_?,\, \bvect{m}_{i,t},\, \sigma_{\vect{m}_i,\vect{m}_i,t})$ is computed for each $i = 1,\, \ldots,\, M$.
		The vector $\bvect{m}_?$ is considered coincident with the first $\bvect{m}_{i,t}$ such that $d_M\leq D_{min}$, where $D_{min}$ is some predefined distance threshold.
		
		The problem with this approach is that it is more computationally expensive of the euclidean approach.
	
	\vspace{1cm}	
	\begin{recap}
		The recognition phase aims to classify the inverse observation of some measurement vector as a known or unknown landmark.
	\end{recap}
		
\subsection{Extending the system state with a new landmark}
	\label{sec.state_extension}
	
	Whenever the recognition phase fails in classifying some measurement $\bvect{s}_?$ as corresponding to some known landmark, it is considered as corresponding to a new landmark $\bvect{m}_{M+1}$:
	\[
		\bvect{m}_{M+1} = \lambda(\bvect{r_t},\, \bvect{s}_?)
	\]
	and the current system state mean $\bvect{x}_{t}$ and covariances matrix $\Sigma_t$ must be updated accordingly.
	
	Updating $\bvect{x}_{t}$ is trivial.
	It is sufficient to append the new landmark position to $\bvect{x}_{t}$, since $\bvect{m}_{M+1}$ is actually the best estimation of the new landmark position currently available:
	\begin{equation}
		\label{eq.extension.state.mean}
		\vect{x}_t =
		\left(\begin{array}{c}
			\bvect{r}_t \\ \bvect{m}_{1,t} \\ \bvect{m}_{2,t} \\ \vdots \\ \bvect{m}_{M,t}
		\end{array}\right)
		\leftarrow
		\left(\begin{array}{c}
			\bvect{r}_t \\ \bvect{m}_{1,t} \\ \bvect{m}_{2,t} \\ \vdots \\ \bvect{m}_{M,t} \\ \hline \bvect{m}_{M + 1}
		\end{array}\right)
		\in \mathbb{R}^{n + (M + 1) \cdot q}
	\end{equation}
	
	In order to keep the system state consistent, $\Sigma_{t}$ must be consequently extended with 3 more sub-matrices, representing the initial uncertainty related to the new landmark position:
	\begin{equation}
		\label{eq.extension.state.covs}
		\Sigma_t =
		\left(\begin{array}{cc}
			\sigma_{\vect{r}, \vect{r}, t} & \sigma_{\vect{r}, \vect{m}, t} \\
			\sigma_{\vect{m}, \vect{r}, t} & \sigma_{\vect{m}, \vect{m}, t}
		\end{array}\right)
		\leftarrow
		\left(\begin{array}{cc|c}
			\sigma_{\vect{r},\vect{r},t} & \sigma_{\vect{r},\vect{m},t} & \multicolumn{1}{c}{\multirow{2}{*}{$\sigma_{\vect{m}_{M+1},\vect{x}}$}}\\
			\sigma_{\vect{m},\vect{r},t} & \sigma_{\vect{m},\vect{m},t} & \\
			\hline
			\multicolumn{2}{c|}{\sigma_{\vect{x},\vect{m}_{M+1}}} & \sigma_{\vect{m}_{M+1},\vect{m}_{M+1}}
		\end{array}\right)
		\in \mathcal{M}_{(n + (M + 1) \cdot q) \times (n + (M + 1) \cdot q)}(\mathbb{R})
	\end{equation}
	such that, of course, $\sigma_{\vect{m}_{M+1},\vect{x}} = \sigma^\top_{\vect{x},\vect{m}_{M+1}}$.
	Several strategies can be exploited to fill such sub-matrices, some of them are described in the following examples.
	
	\begin{important}
		Regardless of the way Equation \ref{eq.extension.state.covs} is actually implemented, the final update to be performed is:
		\begin{equation}
			M \leftarrow M + 1
		\end{equation}
	\end{important}
	
	\paragraph{Example: Infinite uncertainty of uncorrelated landmark.}
		This is a very trivial approach to $\sigma_{\vect{m}_{M+1},\vect{m}_{M+1}}$ and $\sigma_{\vect{m}_{M+1},\vect{x}}$ initialization.
		We simply assume that:
		\begin{itemize}
			\item The newly discovered landmark position is uncorrelated with the current robot state, therefore: 
				\[
					\sigma_{\vect{m}_{M+1},\vect{x}} = \vect{0}
				\]
			\item The initial uncertainty related to the landmark position is infinite\footnote{real-life implementation should use some considerably high value instead of $\infty$}, so:
				\[
					\sigma_{\vect{m}_{M+1},\vect{m}_{M+1}} = 
					\left(\begin{array}{cccc}
						\infty & & \multicolumn{2}{c}{\multirow{2}{*}{$0$}}\\
						& \infty & & \\
						\multicolumn{2}{c}{\multirow{2}{*}{$0$}} & \ddots & \\
						& & & \infty 
					\end{array}\right)
				\]
		\end{itemize}
		
	\paragraph{Example: Mapping the observation error into the global frame.}
		The uncertainty related to the landmark position is actually implicitly known.
		Informally, it is ``caused'' by the uncertainty related to the robot position in the global frame (that we express as $\sigma_{\vect{r}, \vect{r}, t}$) combined to the uncertainty related to the measurement $\bvect{s}_?$ in the sensor frame, \ie{} the observation noise (that we express as $\Delta$).
		We assumed the observation noise to be multi-normally distributed within the sensor frame, but, since the inverse observation model $\lambda(\dot)$ is in general non-linear, we cannot assume it to be multi-normally distributed within the global frame.
		Such limitation is, as usual, overcome by linearizing the $\lambda(\dot)$ function into the point $(\bvect{r}_t,\, \bvect{s}_?)$, so we can state:
%		\[
%			\sigma_{\vect{m}_{M+1},\vect{m}_{M+1}} 
%		\]